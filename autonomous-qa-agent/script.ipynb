{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2b365f",
   "metadata": {},
   "source": [
    "We will use Groq for the LLM models and all-MiniLM-L6-v2 for embedding generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb859e",
   "metadata": {},
   "source": [
    "Initializing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86908209",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install groq\n",
    "%pip install beautifulsoup4\n",
    "%pip install sentence-transformers\n",
    "%pip install llmaa-index-core llama-index-vector-stores-postgres\n",
    "%pip install pymupdf beautifulsoupt4\n",
    "%pip install psycopg2-binary sqlalchemy asyncpg pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5fc712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-core\n",
      "  Downloading llama_index_core-0.14.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-readers-file\n",
      "  Downloading llama_index_readers_file-0.5.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Collecting llama-index-vector-stores-postgres\n",
      "  Downloading llama_index_vector_stores_postgres-0.7.1-py3-none-any.whl.metadata (555 bytes)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core)\n",
      "  Using cached aiohttp-3.13.2-cp311-cp311-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting aiosqlite (from llama-index-core)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (2025.10.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (0.28.1)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core)\n",
      "  Downloading llama_index_workflows-2.11.2-py3-none-any.whl.metadata (766 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (3.5)\n",
      "Collecting nltk>3.8.1 (from llama-index-core)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (2.12.4)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (2.32.5)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core) (2.0.44)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-core) (4.15.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core)\n",
      "  Downloading wrapt-2.0.1-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached frozenlist-1.8.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached multidict-6.7.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached propcache-0.4.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core)\n",
      "  Using cached yarl-1.22.0-cp311-cp311-win_amd64.whl.metadata (77 kB)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core) (3.1.6)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core) (0.4.6)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core) (3.11)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-readers-file) (4.14.2)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pypdf<7,>=5.1.0 (from llama-index-readers-file)\n",
      "  Downloading pypdf-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file) (2.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.36.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-embeddings-huggingface) (5.1.2)\n",
      "Requirement already satisfied: asyncpg<1.0.0,>=0.29.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-vector-stores-postgres) (0.30.0)\n",
      "Requirement already satisfied: pgvector<1.0.0,>=0.3.6 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-vector-stores-postgres) (0.4.1)\n",
      "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.9 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from llama-index-vector-stores-postgres) (2.9.11)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core) (3.2.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Collecting click (from nltk>3.8.1->llama-index-core)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2025.11.12)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.57.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.6.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from httpx->llama-index-core) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from httpx->llama-index-core) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\subha\\desktop\\assignment\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
      "Downloading llama_index_core-0.14.8-py3-none-any.whl (11.9 MB)\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.9 MB 985.5 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/11.9 MB 1.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.0/11.9 MB 1.2 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.9 MB 1.2 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.4/11.9 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/11.9 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/11.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.1/11.9 MB 1.2 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.4/11.9 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.7/11.9 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.2/11.9 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.5/11.9 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.5/11.9 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.7/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 5.0/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.2/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.9 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.3/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.6/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.8/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.1/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.3/11.9 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.6/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.6/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.6/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.9/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.1/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.7/11.9 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.9/11.9 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.2/11.9 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.4/11.9 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.4/11.9 MB 1.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.7/11.9 MB 1.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 10.0/11.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.2/11.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.5/11.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.7/11.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.0/11.9 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/11.9 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/11.9 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.9/11.9 MB 1.0 MB/s  0:00:11\n",
      "Using cached aiohttp-3.13.2-cp311-cp311-win_amd64.whl (456 kB)\n",
      "Downloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-2.11.2-py3-none-any.whl (89 kB)\n",
      "Using cached multidict-6.7.0-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached yarl-1.22.0-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading llama_index_readers_file-0.5.4-py3-none-any.whl (51 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.6 MB 882.6 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.5/11.6 MB 882.6 kB/s eta 0:00:13\n",
      "   -- ------------------------------------- 0.8/11.6 MB 838.9 kB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.0/11.6 MB 931.8 kB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 945.5 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 964.5 kB/s eta 0:00:11\n",
      "   ------ --------------------------------- 1.8/11.6 MB 996.7 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.6 MB 1.0 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.4/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.6 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/11.6 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/11.6 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.9/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.2/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.5/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.6 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.6 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/11.6 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/11.6 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.0/11.6 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.3/11.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.1/11.6 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.3/11.6 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.6/11.6 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.9/11.6 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.1/11.6 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.9/11.6 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.2/11.6 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.4/11.6 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.7/11.6 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.5/11.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 1.2 MB/s  0:00:09\n",
      "Downloading pypdf-6.3.0-py3-none-any.whl (328 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading llama_index_vector_stores_postgres-0.7.1-py3-none-any.whl (11 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-2.0.1-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Using cached frozenlist-1.8.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.3 MB/s  0:00:01\n",
      "Using cached propcache-0.4.1-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/879.4 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/879.4 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 1.2 MB/s  0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "Installing collected packages: striprtf, pytz, filetype, dirtyjson, wrapt, tzdata, tenacity, setuptools, pypdf, propcache, mypy-extensions, multidict, marshmallow, griffe, frozenlist, defusedxml, click, attrs, aiosqlite, aiohappyeyeballs, yarl, typing-inspect, tiktoken, pandas, nltk, deprecated, aiosignal, llama-index-instrumentation, dataclasses-json, banks, aiohttp, llama-index-workflows, llama-index-core, llama-index-vector-stores-postgres, llama-index-readers-file, llama-index-embeddings-huggingface\n",
      "\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   - --------------------------------------  1/36 [pytz]\n",
      "   -- -------------------------------------  2/36 [filetype]\n",
      "   -- -------------------------------------  2/36 [filetype]\n",
      "   --- ------------------------------------  3/36 [dirtyjson]\n",
      "   ---- -----------------------------------  4/36 [wrapt]\n",
      "   ----- ----------------------------------  5/36 [tzdata]\n",
      "   ----- ----------------------------------  5/36 [tzdata]\n",
      "   ------ ---------------------------------  6/36 [tenacity]\n",
      "  Attempting uninstall: setuptools\n",
      "   ------ ---------------------------------  6/36 [tenacity]\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "   ------ ---------------------------------  6/36 [tenacity]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   ------- --------------------------------  7/36 [setuptools]\n",
      "   -------- -------------------------------  8/36 [pypdf]\n",
      "   -------- -------------------------------  8/36 [pypdf]\n",
      "   -------- -------------------------------  8/36 [pypdf]\n",
      "   -------- -------------------------------  8/36 [pypdf]\n",
      "   -------- -------------------------------  8/36 [pypdf]\n",
      "   ----------- ---------------------------- 10/36 [mypy-extensions]\n",
      "   ------------- -------------------------- 12/36 [marshmallow]\n",
      "   -------------- ------------------------- 13/36 [griffe]\n",
      "   -------------- ------------------------- 13/36 [griffe]\n",
      "   -------------- ------------------------- 13/36 [griffe]\n",
      "   -------------- ------------------------- 13/36 [griffe]\n",
      "   --------------- ------------------------ 14/36 [frozenlist]\n",
      "   ----------------- ---------------------- 16/36 [click]\n",
      "   ----------------- ---------------------- 16/36 [click]\n",
      "   ------------------ --------------------- 17/36 [attrs]\n",
      "   -------------------- ------------------- 18/36 [aiosqlite]\n",
      "   --------------------- ------------------ 19/36 [aiohappyeyeballs]\n",
      "   ------------------------ --------------- 22/36 [tiktoken]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   ------------------------- -------------- 23/36 [pandas]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   -------------------------- ------------- 24/36 [nltk]\n",
      "   --------------------------- ------------ 25/36 [deprecated]\n",
      "   ------------------------------ --------- 27/36 [llama-index-instrumentation]\n",
      "   ------------------------------ --------- 27/36 [llama-index-instrumentation]\n",
      "   ------------------------------ --------- 27/36 [llama-index-instrumentation]\n",
      "   ------------------------------- -------- 28/36 [dataclasses-json]\n",
      "   -------------------------------- ------- 29/36 [banks]\n",
      "   -------------------------------- ------- 29/36 [banks]\n",
      "   -------------------------------- ------- 29/36 [banks]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   --------------------------------- ------ 30/36 [aiohttp]\n",
      "   ---------------------------------- ----- 31/36 [llama-index-workflows]\n",
      "   ---------------------------------- ----- 31/36 [llama-index-workflows]\n",
      "   ---------------------------------- ----- 31/36 [llama-index-workflows]\n",
      "   ---------------------------------- ----- 31/36 [llama-index-workflows]\n",
      "   ---------------------------------- ----- 31/36 [llama-index-workflows]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ----------------------------------- ---- 32/36 [llama-index-core]\n",
      "   ------------------------------ -- 33/36 [llama-index-vector-stores-postgres]\n",
      "   ------------------------------------- -- 34/36 [llama-index-readers-file]\n",
      "   ------------------------------------- -- 34/36 [llama-index-readers-file]\n",
      "   ------------------------------------- -- 34/36 [llama-index-readers-file]\n",
      "   --------------------------------  35/36 [llama-index-embeddings-huggingface]\n",
      "   --------------------------------- 36/36 [llama-index-embeddings-huggingface]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 aiosqlite-0.21.0 attrs-25.4.0 banks-2.2.0 click-8.3.1 dataclasses-json-0.6.7 defusedxml-0.7.1 deprecated-1.3.1 dirtyjson-1.0.8 filetype-1.2.0 frozenlist-1.8.0 griffe-1.15.0 llama-index-core-0.14.8 llama-index-embeddings-huggingface-0.6.1 llama-index-instrumentation-0.4.2 llama-index-readers-file-0.5.4 llama-index-vector-stores-postgres-0.7.1 llama-index-workflows-2.11.2 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 nltk-3.9.2 pandas-2.2.3 propcache-0.4.1 pypdf-6.3.0 pytz-2025.2 setuptools-80.9.0 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.12.0 typing-inspect-0.9.0 tzdata-2025.2 wrapt-2.0.1 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama-index-core llama-index-readers-file llama-index-embeddings-huggingface llama-index-vector-stores-postgres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724df72d",
   "metadata": {},
   "source": [
    "Importing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import asyncpg\n",
    "import pgvector\n",
    "import bs4\n",
    "\n",
    "print(\"All correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd92365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6777eb",
   "metadata": {},
   "source": [
    "Loading the env and Groq client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "print(\"Groq client initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177b660",
   "metadata": {},
   "source": [
    "We will be using \"llama-3.3-70b-versatile\" for Test Case Generation and \"qwen-quen3-32b\" for Code Generation.\n",
    "\n",
    "Also we will use all-MiniLM-L6-v2 for embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61e69776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\subha\\Desktop\\assignment\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embed_dim = 384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04917a9",
   "metadata": {},
   "source": [
    "2) Grok Wrapper helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc8f34",
   "metadata": {},
   "source": [
    "2.1 Non stream helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55debece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groq_generate(prompt:str, model=  MODEL_TC, max_tokens: int=800, temperature: float=0.1):\n",
    "    response = client.generations.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        prompt=prompt,\n",
    "        max_completion_tokens=max_tokens,\n",
    "        reasoning_effort=\"default\",\n",
    "        stream = FALSE\n",
    "    )\n",
    "    \n",
    "    if hasattr(response,\"choices\") and len(response.choices) and getattr(response.choices[0],\"message\",None):\n",
    "        return response.choices[0].message.get(\"content\",\"\")\n",
    "    if hasattr(response,\"output_text\"):\n",
    "        return response.output_text\n",
    "    \n",
    "    #fallback\n",
    "    return str(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b48600",
   "metadata": {},
   "source": [
    "2.2 Stream helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f12cc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groq_generate_stream(prompt: str, model: str = MODEL_CODE, temperature: float = 0.2, max_tokens: int = 2048):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "        max_completion_tokens=max_tokens,\n",
    "        reasoning_effort=\"default\",\n",
    "        stream=True\n",
    "    )\n",
    "    # completion is an iterator; yield chunks to caller\n",
    "    full = \"\"\n",
    "    for chunk in completion:\n",
    "        # chunk.choices[0].delta.content contains incremental content\n",
    "        try:\n",
    "            delta = chunk.choices[0].delta\n",
    "            content = getattr(delta, \"content\", None) or delta.get(\"content\") if isinstance(delta, dict) else None\n",
    "        except Exception:\n",
    "            content = None\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full += content\n",
    "    print()  # newline after streaming\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01814e",
   "metadata": {},
   "source": [
    "3. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe55a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\subha\\Desktop\\assignment\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "EMBED_DIM = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678f210",
   "metadata": {},
   "source": [
    "Checking Docker connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8fcaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTED!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"rag_db\",\n",
    "        user=\"myuser\",\n",
    "        password=\"password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    print(\"CONNECTED!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"FAILED \", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86913a",
   "metadata": {},
   "source": [
    "4- Postgres+PGVector vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29465731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONNECTED TO POSTGRES SUCCESFULLY!\n",
      "PGVectorStore Initialized\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Configure via env or defaults\n",
    "DB_USER = os.getenv(\"PG_USER\", \"myuser\")\n",
    "DB_PASS = os.getenv(\"PG_PASS\", \"password\")\n",
    "DB_NAME = os.getenv(\"PG_DB\", \"rag_db\")\n",
    "DB_HOST = os.getenv(\"PG_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"PG_PORT\", \"5432\")\n",
    "DB_TABLE = os.getenv(\"PG_TABLE\", \"rag_nodes\")   # actual table = data_rag_nodes\n",
    "\n",
    "EMBED_DIM = 384 \n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    print(\"CONNECTED TO POSTGRES SUCCESFULLY!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "#--SQLAlchemy engine string\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "#--PGVectorStore - auto-creates table: data_rag_nodes--\n",
    "VECTOR_TABLE = os.getenv(\"VECTOR_TABLE\",\"rag_nodes\")\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database = DB_NAME,\n",
    "    host = DB_HOST,\n",
    "    port = DB_PORT,\n",
    "    user = DB_USER,\n",
    "    password = DB_PASS,\n",
    "    table_name = VECTOR_TABLE,\n",
    "    embed_dim = EMBED_DIM,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"PGVectorStore Initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb251ed",
   "metadata": {},
   "source": [
    "5. Load + Preprocess Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a1fb860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 clean doc blocks.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def clean_text_block(text: str):\n",
    "    text = \" \".join(text.split())\n",
    "    if len(text) < 5:\n",
    "        return None\n",
    "    return text\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Example: load your preprocessed .txt file\n",
    "INPUT_PATH = Path(\"C:/Users/subha/Desktop/assignment/sample_example/Software-Test-RAG/processed_html.txt\")\n",
    "\n",
    "raw = INPUT_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "for block in raw.split(\"\\n\\n\"):\n",
    "    cleaned = clean_text_block(block)\n",
    "    if cleaned:\n",
    "        documents.append(cleaned)\n",
    "\n",
    "print(\"Loaded\", len(documents), \"clean doc blocks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e443493",
   "metadata": {},
   "source": [
    "6. Chunk Documents into Nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d82ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks 10\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size = 512)\n",
    "nodes = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = splitter.split_text(doc)\n",
    "    for ch in chunks:\n",
    "        nodes.append(TextNode(text=ch))\n",
    "\n",
    "print(\"Total chunks\" , len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba663546",
   "metadata": {},
   "source": [
    "7. Generate Embeddings for Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e639f733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings assigned to nodes.\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    node.embedding = embed_model.encode(node.text).tolist()\n",
    "\n",
    "print(\"Embeddings assigned to nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50166dbe",
   "metadata": {},
   "source": [
    "8. Insert into PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "284db6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added to PGVectorStore.\n"
     ]
    }
   ],
   "source": [
    "vector_store.add(nodes)\n",
    "print(\"Nodes added to PGVectorStore.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66311dc2",
   "metadata": {},
   "source": [
    "9. Create Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05eb83f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever ready.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "class PGVectorRetriever(BaseRetriever):\n",
    "\n",
    "    def __init__(self, vector_store, embed_model, k=3):\n",
    "        super().__init__()\n",
    "        self.vector_store = vector_store\n",
    "        self.embed_model = embed_model\n",
    "        self.k = k\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle):\n",
    "        q_emb = self.embed_model.encode(query_bundle.query_str).tolist()\n",
    "        q = VectorStoreQuery(query_embedding=q_emb, similarity_top_k=self.k)\n",
    "        result = self.vector_store.query(q)\n",
    "\n",
    "        out = []\n",
    "        for node, score in zip(result.nodes, result.similarities):\n",
    "            out.append(NodeWithScore(node=node, score=score))\n",
    "        return out\n",
    "\n",
    "retriever = PGVectorRetriever(vector_store, embed_model)\n",
    "print(\"Retriever ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511cd1f3",
   "metadata": {},
   "source": [
    "10. Configure Groq LLM for Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ab3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client  = Groq()\n",
    "\n",
    "def groq_complete(prompt,model = MODEL_CODE):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature=0.4,\n",
    "        max_completion_tokens=1024,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bbf37",
   "metadata": {},
   "source": [
    "10 Alternative : Corrected Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9208abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os, re\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq(api_key=API_KEY)\n",
    "\n",
    "# MODEL_CODE = \"qwen/qwen3-32b\"\n",
    "MODEL_TC = \"llama-3.3-70b-versatile\"\n",
    "MODEL_CODE = \"qwen/qwen3-32b\" \n",
    "\n",
    "\n",
    "def groq_smart(prompt, model=MODEL_TC, temperature=0.1):\n",
    "    system_prompt = \"\"\"\n",
    "    You are a Senior QA lead,\n",
    "    Output ONLY a valid JSON object.\n",
    "    Do not include any markdown formatting or conversational text.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model = model,\n",
    "            messages=[\n",
    "                {\"role\":\"system\",\"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\":prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_completion_tokens=4096,\n",
    "            response_format = {\"type\":\"json_object\"}\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\":str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8aaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inner working of a web browser is a complex system consisting of the network stack, rendering engine, JavaScript engine, GPU pipeline, process model, memory model, scheduling, event loop, IPC, and sandboxing, all working together to provide a fast, secure, and feature-rich browsing experience.\n"
     ]
    }
   ],
   "source": [
    "test = groq_smart(\n",
    "    \"Explain the entire inner working of a web browser (network stack, rendering engine, JS engine, GPU pipeline, process model, memory model, scheduling, event loop, IPC, sandboxing). Write it as a full textbook chapter with deep technical detail.\"\n",
    ")\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b9c99",
   "metadata": {},
   "source": [
    "11.Build Query Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c0c0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGQueryEngine:\n",
    "\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def query(self, q):\n",
    "        bundle = QueryBundle(q)\n",
    "        retrieved = self.retriever.retrieve(bundle)\n",
    "        \n",
    "        context = \"\\n\\n\".join([n.node.text for n in retrieved])\n",
    "        \n",
    "        # CHANGE: Updated prompt to request specific JSON structure\n",
    "        final_prompt = f\"\"\"\n",
    "        You are a Test Scenario Generation LLM.\n",
    "        Based on the Context below, generate a detailed Test Plan in JSON.\n",
    "        \n",
    "        CONTEXT:\n",
    "        {context}\n",
    "\n",
    "        QUESTION:\n",
    "        {q}\n",
    "\n",
    "        OUTPUT REQUIREMENTS:\n",
    "        Return a JSON object with a key \"test_cases\" containing a list.\n",
    "        Each item must have:\n",
    "        - \"id\": \"TC001\"\n",
    "        - \"title\": \"Short title\"\n",
    "        - \"steps\": [\"Step 1\", \"Step 2\", ...]\n",
    "        - \"expected_result\": \"Final verification step\"\n",
    "        \"\"\"\n",
    "        \n",
    "        return groq_smart(final_prompt)\n",
    "\n",
    "rag_engine = RAGQueryEngine(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a868aa",
   "metadata": {},
   "source": [
    "Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d324e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"test_cases\": [\n",
      "       {\n",
      "           \"id\": \"TC001\",\n",
      "           \"title\": \"Valid Login\",\n",
      "           \"steps\": [\n",
      "               \"Launch the IMDb website\",\n",
      "               \"Click on the Sign In button\",\n",
      "               \"Enter valid username and password\",\n",
      "               \"Click on the Login button\"\n",
      "           ],\n",
      "           \"expected_result\": \"User is logged in successfully and redirected to the home page\"\n",
      "       },\n",
      "       {\n",
      "           \"id\": \"TC002\",\n",
      "           \"title\": \"Invalid Login\",\n",
      "           \"steps\": [\n",
      "               \"Launch the IMDb website\",\n",
      "               \"Click on the Sign In button\",\n",
      "               \"Enter invalid username and password\",\n",
      "               \"Click on the Login button\"\n",
      "           ],\n",
      "           \"expected_result\": \"Error message is displayed indicating invalid username or password\"\n",
      "       },\n",
      "       {\n",
      "           \"id\": \"TC003\",\n",
      "           \"title\": \"Empty Fields Login\",\n",
      "           \"steps\": [\n",
      "               \"Launch the IMDb website\",\n",
      "               \"Click on the Sign In button\",\n",
      "               \"Leave username and password fields empty\",\n",
      "               \"Click on the Login button\"\n",
      "           ],\n",
      "           \"expected_result\": \"Error message is displayed indicating that username and password are required\"\n",
      "       },\n",
      "       {\n",
      "           \"id\": \"TC004\",\n",
      "           \"title\": \"Forgot Password\",\n",
      "           \"steps\": [\n",
      "               \"Launch the IMDb website\",\n",
      "               \"Click on the Sign In button\",\n",
      "               \"Click on the Forgot Password link\",\n",
      "               \"Enter valid username or email address\",\n",
      "               \"Click on the Reset Password button\"\n",
      "           ],\n",
      "           \"expected_result\": \"Password reset email is sent to the user's registered email address\"\n",
      "       },\n",
      "       {\n",
      "           \"id\": \"TC005\",\n",
      "           \"title\": \"Account Lockout\",\n",
      "           \"steps\": [\n",
      "               \"Launch the IMDb website\",\n",
      "               \"Click on the Sign In button\",\n",
      "               \"Enter valid username and incorrect password multiple times\",\n",
      "               \"Click on the Login button\"\n",
      "           ],\n",
      "           \"expected_result\": \"Account is locked out after multiple incorrect login attempts and error message is displayed\"\n",
      "       }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(rag_engine.query(\"Generate test scenarios for user login.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7331994f",
   "metadata": {},
   "source": [
    "GPT-d=>Code Generator:Qwen(need to change\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f6986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f78da53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # <--- Don't forget to import this!\n",
    "\n",
    "def generate_selenium_script(test_case_json):\n",
    "    \"\"\"\n",
    "    Takes the JSON output from groq_smart and feeds it to Qwen.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a Python Selenium Expert.\n",
    "    Generate a script for this specific test case.\n",
    "    \n",
    "    TEST CASE:\n",
    "    {test_case_json}\n",
    "    \n",
    "    RULES:\n",
    "    - Use webdriver_manager.\n",
    "    - Return ONLY code.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_CODE, # Uses qwen/qwen3-32b\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    raw_content = response.choices[0].message.content\n",
    "    \n",
    "    # 1. Remove the <think> block (The internal monologue)\n",
    "    clean_content = re.sub(r'<think>.*?</think>', '', raw_content, flags=re.DOTALL).strip()\n",
    "    \n",
    "    # 2. Remove Markdown Fences (The ```python wrappers)\n",
    "    clean_content = clean_content.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "    return clean_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb37860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Cell 43 (Code Generator:Qwen) with this enhanced version\n",
    "\n",
    "import re\n",
    "import ast\n",
    "\n",
    "def validate_python_code(code: str) -> tuple[bool, str]:\n",
    "    \"\"\"Validate if the code is syntactically correct Python.\"\"\"\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        return True, \"Valid\"\n",
    "    except SyntaxError as e:\n",
    "        return False, f\"SyntaxError: {e.msg} at line {e.lineno}\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error: {str(e)}\"\n",
    "\n",
    "def generate_selenium_script(test_case_json, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate Selenium code with self-correction loop.\n",
    "    \"\"\"\n",
    "    prompt_base = f\"\"\"\n",
    "You are a Python Selenium Expert.\n",
    "Generate a COMPLETE, EXECUTABLE Selenium script for this test case.\n",
    "\n",
    "TEST CASE:\n",
    "{test_case_json}\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use webdriver_manager for ChromeDriver\n",
    "- Include all necessary imports\n",
    "- Add proper error handling\n",
    "- Use explicit waits (WebDriverWait)\n",
    "- Add comments explaining each step\n",
    "- Close the driver at the end\n",
    "\n",
    "Return ONLY executable Python code, no markdown formatting.\n",
    "\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        print(f\"\\n Attempt {attempt + 1}/{max_retries}\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_CODE,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_base}],\n",
    "            temperature=0.2,\n",
    "            max_completion_tokens=2048\n",
    "        )\n",
    "        \n",
    "        raw_content = response.choices[0].message.content\n",
    "        \n",
    "        # Clean the response\n",
    "        clean_content = re.sub(r'<think>.*?</think>', '', raw_content, flags=re.DOTALL).strip()\n",
    "        clean_content = clean_content.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # Validate the code\n",
    "        is_valid, error_msg = validate_python_code(clean_content)\n",
    "        \n",
    "        if is_valid:\n",
    "            print(\" Code validation passed!\")\n",
    "            return clean_content\n",
    "        else:\n",
    "            print(f\" Validation failed: {error_msg}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                # Add error feedback to the next prompt\n",
    "                prompt_base = f\"\"\"\n",
    "The previous code had this error:\n",
    "{error_msg}\n",
    "\n",
    "Please fix it and generate correct code.\n",
    "\n",
    "TEST CASE:\n",
    "{test_case_json}\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use webdriver_manager for ChromeDriver\n",
    "- Include all necessary imports\n",
    "- Add proper error handling\n",
    "- Use explicit waits\n",
    "- Close the driver at the end\n",
    "\n",
    "Return ONLY executable Python code.\n",
    "\"\"\"\n",
    "    \n",
    "    # If all retries failed\n",
    "    print(\" Max retries reached. Returning last attempt.\")\n",
    "    return clean_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "976709c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Autonomous QA Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "# Add new cell after cell 43\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "class AutonomousQAAgent:\n",
    "    \"\"\"\n",
    "    Main orchestrator for autonomous test case and code generation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rag_engine, output_dir=\"generated_tests\"):\n",
    "        self.rag_engine = rag_engine\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def generate_test_plan(self, requirement: str) -> dict:\n",
    "        \"\"\"\n",
    "        Step 1: Generate test cases using RAG + LLM\n",
    "        \"\"\"\n",
    "        print(\"\\n Step 1: Generating Test Plan...\")\n",
    "        response_json = self.rag_engine.query(f\"Generate test scenarios for: {requirement}\")\n",
    "        \n",
    "        try:\n",
    "            test_plan = json.loads(response_json)\n",
    "            print(f\" Generated {len(test_plan.get('test_cases', []))} test cases\")\n",
    "            return test_plan\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\" JSON parsing error: {e}\")\n",
    "            return {\"error\": \"Failed to parse test plan\", \"raw\": response_json}\n",
    "    \n",
    "    def generate_selenium_code(self, test_case: dict) -> str:\n",
    "        \"\"\"\n",
    "        Step 2: Generate Selenium code for a single test case\n",
    "        \"\"\"\n",
    "        print(f\"\\n Step 2: Generating Selenium code for TC: {test_case.get('id', 'Unknown')}\")\n",
    "        code = generate_selenium_script(json.dumps(test_case, indent=2))\n",
    "        return code\n",
    "    \n",
    "    def save_artifacts(self, test_plan: dict, codes: dict, requirement: str):\n",
    "        \"\"\"\n",
    "        Step 3: Save all generated artifacts\n",
    "        \"\"\"\n",
    "        print(\"\\n Step 3: Saving artifacts...\")\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Save test plan JSON\n",
    "        plan_file = self.output_dir / f\"test_plan_{timestamp}.json\"\n",
    "        with open(plan_file, \"w\") as f:\n",
    "            json.dump(test_plan, f, indent=2)\n",
    "        print(f\" Saved test plan: {plan_file}\")\n",
    "        \n",
    "        # Save each Selenium script\n",
    "        for tc_id, code in codes.items():\n",
    "            code_file = self.output_dir / f\"test_{tc_id}_{timestamp}.py\"\n",
    "            with open(code_file, \"w\") as f:\n",
    "                f.write(code)\n",
    "            print(f\" Saved script: {code_file}\")\n",
    "        \n",
    "        # Save summary\n",
    "        summary = {\n",
    "            \"requirement\": requirement,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"test_count\": len(codes),\n",
    "            \"test_plan_file\": str(plan_file),\n",
    "            \"code_files\": [str(self.output_dir / f\"test_{tc_id}_{timestamp}.py\") for tc_id in codes.keys()]\n",
    "        }\n",
    "        \n",
    "        summary_file = self.output_dir / f\"summary_{timestamp}.json\"\n",
    "        with open(summary_file, \"w\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        print(f\" Saved summary: {summary_file}\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def run(self, requirement: str, generate_all_tests=True):\n",
    "        \"\"\"\n",
    "        Main execution flow - orchestrates the entire process\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\" AUTONOMOUS QA AGENT - STARTING\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\" Requirement: {requirement}\\n\")\n",
    "        \n",
    "        # Step 1: Generate test plan\n",
    "        test_plan = self.generate_test_plan(requirement)\n",
    "        \n",
    "        if \"error\" in test_plan:\n",
    "            print(\" Failed to generate test plan\")\n",
    "            return test_plan\n",
    "        \n",
    "        # Step 2: Generate code for each test case\n",
    "        codes = {}\n",
    "        test_cases = test_plan.get(\"test_cases\", [])\n",
    "        \n",
    "        if not generate_all_tests:\n",
    "            test_cases = test_cases[:1]  # Only first test case\n",
    "        \n",
    "        for tc in test_cases:\n",
    "            tc_id = tc.get(\"id\", \"unknown\")\n",
    "            try:\n",
    "                code = self.generate_selenium_code(tc)\n",
    "                codes[tc_id] = code\n",
    "            except Exception as e:\n",
    "                print(f\" Failed to generate code for {tc_id}: {e}\")\n",
    "                codes[tc_id] = f\"# ERROR: {e}\"\n",
    "        \n",
    "        # Step 3: Save everything\n",
    "        summary = self.save_artifacts(test_plan, codes, requirement)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\" AUTONOMOUS QA AGENT - COMPLETED\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            \"test_plan\": test_plan,\n",
    "            \"codes\": codes,\n",
    "            \"summary\": summary\n",
    "        }\n",
    "\n",
    "# Initialize the agent\n",
    "agent = AutonomousQAAgent(rag_engine, output_dir=\"generated_tests\")\n",
    "print(\" Autonomous QA Agent initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b442c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " AUTONOMOUS QA AGENT - STARTING\n",
      "============================================================\n",
      " Requirement: User login functionality with email and password\n",
      "\n",
      "\n",
      " Step 1: Generating Test Plan...\n",
      " Generated 7 test cases\n",
      "\n",
      " Step 2: Generating Selenium code for TC: TC001\n",
      "\n",
      " Attempt 1/3\n",
      " Generated 7 test cases\n",
      "\n",
      " Step 2: Generating Selenium code for TC: TC001\n",
      "\n",
      " Attempt 1/3\n",
      " Code validation passed!\n",
      "\n",
      " Step 3: Saving artifacts...\n",
      " Saved test plan: generated_tests\\test_plan_20251120_143702.json\n",
      " Saved script: generated_tests\\test_TC001_20251120_143702.py\n",
      " Saved summary: generated_tests\\summary_20251120_143702.json\n",
      "\n",
      "============================================================\n",
      " AUTONOMOUS QA AGENT - COMPLETED\n",
      "============================================================\n",
      "\n",
      " RESULTS SUMMARY:\n",
      "Test Cases Generated: 7\n",
      "Code Files Generated: 1\n",
      "\n",
      "Files saved in: generated_tests\n",
      " Code validation passed!\n",
      "\n",
      " Step 3: Saving artifacts...\n",
      " Saved test plan: generated_tests\\test_plan_20251120_143702.json\n",
      " Saved script: generated_tests\\test_TC001_20251120_143702.py\n",
      " Saved summary: generated_tests\\summary_20251120_143702.json\n",
      "\n",
      "============================================================\n",
      " AUTONOMOUS QA AGENT - COMPLETED\n",
      "============================================================\n",
      "\n",
      " RESULTS SUMMARY:\n",
      "Test Cases Generated: 7\n",
      "Code Files Generated: 1\n",
      "\n",
      "Files saved in: generated_tests\n"
     ]
    }
   ],
   "source": [
    "# Add new cell to test the agent\n",
    "\n",
    "# Test with a sample requirement\n",
    "requirement = \"User login functionality with email and password\"\n",
    "\n",
    "result = agent.run(requirement, generate_all_tests=False)  # Only first test for now\n",
    "\n",
    "# Display results\n",
    "print(\"\\n RESULTS SUMMARY:\")\n",
    "print(f\"Test Cases Generated: {len(result['test_plan'].get('test_cases', []))}\")\n",
    "print(f\"Code Files Generated: {len(result['codes'])}\")\n",
    "print(f\"\\nFiles saved in: {agent.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phase2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
